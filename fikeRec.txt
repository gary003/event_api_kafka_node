--- File: ./.c8rc.json ---
{

  "include": ["src/v1"],

  "thresholds": {

    "branches": 80,

    "lines": 85,

    "functions": 90,

    "statements": 85

  }

}

./tsconfig.json

{

    "compilerOptions": {

      /* Visit https://aka.ms/tsconfig.json to read more about this file */

  

      /* Projects */

      // "incremental": true,                              /* Enable incremental compilation */

      // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */

      // "tsBuildInfoFile": "./",                          /* Specify the folder for .tsbuildinfo incremental compilation files. */

      // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects */

      // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */

      // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */

  

      /* Language and Environment */

      "target": "es2017" /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */,

      // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */

      // "jsx": "preserve",                                /* Specify what JSX code is generated. */

      "experimentalDecorators": true /* Enable experimental support for TC39 stage 2 draft decorators. */,

      "emitDecoratorMetadata": true /* Emit design-type metadata for decorated declarations in source files. */,

      // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h' */

      // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */

      // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using `jsx: react-jsx*`.` */

      // "reactNamespace": "",                             /* Specify the object invoked for `createElement`. This only applies when targeting `react` JSX emit. */

      // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */

      // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */

  

      /* Modules */

      "module": "commonjs" /* Specify what module code is generated. */,

      // "rootDir": "./src" /* Specify the root folder within your source files. */,

      "moduleResolution": "node" /* Specify how TypeScript looks up a file from a given module specifier. */,

      // "baseUrl": "./",                                  /* Specify the base directory to resolve non-relative module names. */

      // "paths": {},                                      /* Specify a set of entries that re-map imports to additional lookup locations. */

      // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */

      // "typeRoots": [],                                  /* Specify multiple folders that act like `./node_modules/@types`. */

      // "types": [],                                      /* Specify type package names to be included without being referenced in a source file. */

      // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */

      "resolveJsonModule": true /* Enable importing .json files */,

      // "noResolve": true,                                /* Disallow `import`s, `require`s or `<reference>`s from expanding the number of files TypeScript should add to a project. */

  

      /* JavaScript Support */

      // "allowJs": true,                                  /* Allow JavaScript files to be a part of your program. Use the `checkJS` option to get errors from these files. */

      // "checkJs": true,                                  /* Enable error reporting in type-checked JavaScript files. */

      // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from `node_modules`. Only applicable with `allowJs`. */

  

      /* Emit */

      // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */

      // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */

      // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */

      // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */

      // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If `declaration` is true, also designates a file that bundles all .d.ts output. */

      "outDir": "./dist" /* Specify an output folder for all emitted files. */,

      // "removeComments": true,                           /* Disable emitting comments. */

      // "noEmit": true,                                   /* Disable emitting files from a compilation. */

      // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */

      // "importsNotUsedAsValues": "remove",               /* Specify emit/checking behavior for imports that are only used for types */

      // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */

      // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */

      // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */

      // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */

      // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */

      // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */

      // "newLine": "crlf",                                /* Set the newline character for emitting files. */

      // "stripInternal": true,                            /* Disable emitting declarations that have `@internal` in their JSDoc comments. */

      // "noEmitHelpers": true,                            /* Disable generating custom helper functions like `__extends` in compiled output. */

      // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */

      // "preserveConstEnums": true,                       /* Disable erasing `const enum` declarations in generated code. */

      // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */

  

      /* Interop Constraints */

      // "isolatedModules": true,                          /* Ensure that each file can be safely transpiled without relying on other imports. */

      // "allowSyntheticDefaultImports": true,             /* Allow 'import x from y' when a module doesn't have a default export. */

      "esModuleInterop": true /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables `allowSyntheticDefaultImports` for type compatibility. */,

      // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */

      "forceConsistentCasingInFileNames": true /* Ensure that casing is correct in imports. */,

  

      /* Type Checking */

      "strict": true /* Enable all strict type-checking options. */,

      // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied `any` type.. */

      // "strictNullChecks": true,                         /* When type checking, take into account `null` and `undefined`. */

      // "strictFunctionTypes": true,                      /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */

      // "strictBindCallApply": true,                      /* Check that the arguments for `bind`, `call`, and `apply` methods match the original function. */

      // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */

      // "noImplicitThis": true,                           /* Enable error reporting when `this` is given the type `any`. */

      // "useUnknownInCatchVariables": true,               /* Type catch clause variables as 'unknown' instead of 'any'. */

      "alwaysStrict": true /* Ensure 'use strict' is always emitted. */,

      // "noUnusedLocals": true /* Enable error reporting when a local variables aren't read. */,

      // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read */

      // "exactOptionalPropertyTypes": true,               /* Interpret optional property types as written, rather than adding 'undefined'. */

      "noImplicitReturns": true /* Enable error reporting for codepaths that do not explicitly return in a function. */,

      // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */

      "noUncheckedIndexedAccess": true /* Include 'undefined' in index signature results */,

      // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */

      // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type */

      // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */

      // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */

  

      /* Completeness */

      // "skipDefaultLibCheck": true,                      /* Skip type checking .d.ts files that are included with TypeScript. */

      "skipLibCheck": true /* Skip type checking all .d.ts files. */

    },

    "include": ["./src/**/*"]

  }

  ./fikeRec.txt

./dist/bin/server.js

"use strict";

var __importDefault = (this && this.__importDefault) || function (mod) {

    return (mod && mod.__esModule) ? mod : { "default": mod };

};

Object.defineProperty(exports, "__esModule", { value: true });

const http_1 = __importDefault(require("http"));

const app_1 = __importDefault(require("../app"));

const consumer_1 = require("../messageQ/consumer");

const initMQ_1 = require("../messageQ/initMQ");

// Create HTTP server

const server = http_1.default.createServer(app_1.default);

// Normalize port

const port = normalizePort(process.env.PORT || '3000');

// Check Kafka connectivity by connecting producer and sending a test message

const checkKafkaConnectivity = async () => {

    try {

        await initMQ_1.producer.connect();

        // Optional: Send a test message to ensure topic creation and broker readiness

        await initMQ_1.producer.send({

            topic: 'test-connectivity',

            messages: [{ value: JSON.stringify({ test: 'ping' }) }]

        });

        console.info('Kafka broker is fully reachable and operational');

        await initMQ_1.producer.disconnect();

        return true;

    }

    catch (error) {

        console.error('Kafka broker not reachable:', error);

        return false;

    }

};

// Start Kafka consumer with retry and connectivity check

const startConsumerWithRetry = async (retries = 5, delay = 5000) => {

    for (let attempt = 1; attempt <= retries; attempt++) {

        console.info(`Checking Kafka connectivity (attempt ${attempt}/${retries})`);

        const kafkaReady = await checkKafkaConnectivity();

        if (kafkaReady) {

            try {

                console.info('Starting Kafka consumer...');

                await (0, consumer_1.runConsumer)();

                console.info('Kafka consumer started successfully');

                return;

            }

            catch (err) {

                console.error(`Failed to start Kafka consumer: ${err}`);

            }

        }

        else {

            console.warn('Kafka not fully ready yet');

        }

        if (attempt === retries) {

            console.error('Max retries reached. Exiting...');

            process.exit(1);

        }

        console.info(`Retrying in ${delay / 1000} seconds...`);

        await new Promise((resolve) => setTimeout(resolve, delay));

    }

};

// Start server and consumer

const startServer = async () => {

    try {

        await startConsumerWithRetry();

        server.listen(port);

    }

    catch (err) {

        console.error('Unexpected error starting server:', err);

        process.exit(1);

    }

};

startServer();

server.on('error', onError);

server.on('listening', onListening);

// Handle graceful shutdown

process.on('SIGTERM', () => shutdown('SIGTERM'));

process.on('SIGINT', () => shutdown('SIGINT'));

/**

 * Normalize a port into a number, string, or false.

 */

function normalizePort(val) {

    const portNum = parseInt(val, 10);

    if (isNaN(portNum)) {

        return val;

    }

    if (portNum >= 0) {

        return portNum;

    }

    return false;

}

/**

 * Event listener for HTTP server "error" event.

 */

function onError(error) {

    if (error.syscall !== 'listen') {

        throw error;

    }

    const bind = typeof port === 'string' ? `Pipe ${port}` : `Port ${port}`;

    if (error.code === 'EACCES') {

        console.error(`${bind} requires elevated privileges`);

        process.exit(1);

    }

    else if (error.code === 'EADDRINUSE') {

        console.error(`${bind} is already in use`);

        process.exit(1);

    }

    else {

        throw error;

    }

}

/**

 * Event listener for HTTP server "listening" event.

 */

function onListening() {

    const addr = server.address();

    const bind = typeof addr === 'string' ? `pipe ${addr}` : `port ${addr === null || addr === void 0 ? void 0 : addr.port}`;

    console.info(`Server listening on ${bind}`);

}

/**

 * Graceful shutdown handler

 */

function shutdown(signal) {

    console.info(`Received ${signal}. Shutting down gracefully...`);

    server.close(() => {

        console.info('HTTP server closed.');

        process.exit(0);

    });

    setTimeout(() => {

        console.error('Could not close connections in time, forcefully shutting down');

        process.exit(1);

    }, 10000);

}

./dist/routes/eventRoutes.js

"use strict";

var __importDefault = (this && this.__importDefault) || function (mod) {

    return (mod && mod.__esModule) ? mod : { "default": mod };

};

Object.defineProperty(exports, "__esModule", { value: true });

const express_1 = __importDefault(require("express"));

const router = express_1.default.Router();

router.route('/').get((_, res) => {

    res.status(200).json({ data: 2 });

});

exports.default = router;

./dist/app.js

"use strict";

var __importDefault = (this && this.__importDefault) || function (mod) {

    return (mod && mod.__esModule) ? mod : { "default": mod };

};

Object.defineProperty(exports, "__esModule", { value: true });

const express_1 = __importDefault(require("express"));

const cors_1 = __importDefault(require("cors"));

const helmet_1 = __importDefault(require("helmet"));

const dotenv_1 = __importDefault(require("dotenv"));

const eventRoutes_1 = __importDefault(require("./routes/eventRoutes"));

// Load environment variables

dotenv_1.default.config();

// Initialize Express app

const app = (0, express_1.default)();

// Middleware

app.use((0, helmet_1.default)()); // Security headers

app.use((0, cors_1.default)()); // Enable CORS for cross-origin requests

app.use(express_1.default.json()); // Parse JSON bodies

app.use(express_1.default.urlencoded({ extended: true })); // Parse URL-encoded bodies

// Routes

app.use('/api/events', eventRoutes_1.default); // Event-related endpoints

// Health check endpoint

app.get('/health', (req, res) => {

    res.status(200).json({ status: 'OK', uptime: process.uptime() });

});

// Handle 404 errors

app.use((req, res) => {

    res.status(404).json({ message: 'Route not found' });

});

exports.default = app;

./dist/messageQ/consumer.js

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });

exports.runConsumer = void 0;

const initMQ_1 = require("./initMQ");

const runConsumer = async () => {

    try {

        await initMQ_1.consumer.connect();

        await initMQ_1.consumer.subscribe({ topic: 'event.created', fromBeginning: true });

        await initMQ_1.consumer.run({

            eachMessage: async ({ message }) => {

                try {

                    const eventData = '{????????????????}' + message;

                    //   await EventModel.create({

                    //     type: eventData.type,

                    //     data: eventData.data,

                    //     source: eventData.source || 'kafka'

                    //   })

                    console.info(`Processed event: ${eventData} ; message : ${message} on topic`);

                }

                catch (error) {

                    console.error('Error processing message on topic -!!!!!!!!!!!!!!!!!!!!!!!!!!!:', error);

                }

            }

        });

    }

    catch (error) {

        console.error('Kafka consumer error:', error);

        throw error;

    }

};

exports.runConsumer = runConsumer;

// Handle consumer shutdown

process.on('SIGTERM', async () => {

    console.info('Disconnecting Kafka consumer...');

    await initMQ_1.consumer.disconnect();

    console.info('Kafka consumer disconnected');

});

./dist/messageQ/initMQ.js

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });

exports.consumer = exports.producer = void 0;

const kafkajs_1 = require("kafkajs");

// Initialize Kafka client

const kafka = new kafkajs_1.Kafka({

    clientId: 'event-api',

    brokers: [process.env.KAFKA_BROKERS || ''] // e.g., ['kafka:9092']

});

// Create producer with legacy partitioner to avoid warning

exports.producer = kafka.producer({

    createPartitioner: kafkajs_1.Partitioners.LegacyPartitioner

});

// Create consumer

exports.consumer = kafka.consumer({ groupId: 'event-group' });

./dist/messageQ/producer.js

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });

exports.publishEvent = void 0;

const initMQ_1 = require("./initMQ");

/**

 * Publish an event to a Kafka topic

 */

const publishEvent = async (topic, message) => {

    try {

        await initMQ_1.producer.connect();

        await initMQ_1.producer.send({

            topic,

            messages: [{ value: JSON.stringify(message) }]

        });

        console.info(`Published event to topic ${topic}`);

    }

    catch (error) {

        console.error(`Failed to publish event to ${topic}:`, error);

        throw error;

    }

    finally {

        await initMQ_1.producer.disconnect();

    }

};

exports.publishEvent = publishEvent;

./dist/data_generator/index.js

"use strict";

Object.defineProperty(exports, "__esModule", { value: true });

const promises_1 = require("timers/promises");

const REQUEST_INTERVAL = 6000;

let lastRequestTime = 0;

const fetchWithRateLimit = async () => {

    const planetsArr = ['nova', 'black hole', 'star', 'comet', 'dwarf'];

    const planetsCount = Math.floor(Math.random() * 1000);

    const planetIndex = Math.floor(Math.random() * planetsArr.length);

    const data = `Found in picture - ${planetsCount} ${planetsArr[planetIndex]}(s)`;

    return {

        data,

        timestamp: Date.now()

    };

};

const run = async () => {

    while (true) {

        const now = Date.now();

        const timeSinceLastRequest = now - lastRequestTime;

        // Enforce rate limiting

        if (timeSinceLastRequest < REQUEST_INTERVAL) {

            const waitTime = REQUEST_INTERVAL - timeSinceLastRequest;

            await (0, promises_1.setTimeout)(waitTime);

        }

        const response = await fetchWithRateLimit().catch((err) => null);

        await (0, promises_1.setTimeout)(REQUEST_INTERVAL);

        // console.log({response})

        if (!!response) {

            console.log(`Astronomy - ${JSON.stringify(response)}`);

            lastRequestTime = Number(response.timestamp);

            // Add your Kafka producer logic here:

            // await producer.send({...});

        }

    }

};

run().catch(console.error);

./.prettierrc

{

  "semi": false,

  "singleQuote": true,

  "trailingComma": "none",

  "printWidth": 180,

  "tabWidth": 2,

  "useTabs": false,

  "jsxSingleQuote": true,

  "arrowParens": "always",

  "endOfLine": "auto"

}

./docker-compose.yaml

services:



  zookeeper:

    image: confluentinc/cp-zookeeper:7.9.0

    hostname: zookeeper

    container_name: zookeeper

    environment:

      ZOOKEEPER_CLIENT_PORT: 2181

      ZOOKEEPER_TICK_TIME: 2000

    ports:

      - '2181:2181'

    volumes:

      - zookeeper-data:/var/lib/zookeeper/data

      - zookeeper-log:/var/lib/zookeeper/log

    networks:

      - kafka-net



  api:

    image: confluentinc/cp-kafka:7.9.0

    hostname: kafka

    container_name: kafka

    depends_on:

      zookeeper:

        condition: service_healthy

    environment:

      KAFKA_BROKER_ID: 1

      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      KAFKA_DELETE_TOPIC_ENABLE: "true"

      KAFKA_LOG_RETENTION_HOURS: 168

      KAFKA_NUM_PARTITIONS: 1

      KAFKA_DEFAULT_REPLICATION_FACTOR: 1

      PORT: 3000

    ports:

      - '9092:9092'

      - '29092:29092'

      - '3000:3000'

    volumes:

      - kafka-data:/var/lib/kafka/data

    healthcheck:

      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]

      interval: 10s

      timeout: 5s

      retries: 5

      start_period: 30s

    networks:

      - kafka-net



volumes:

  zookeeper-data:

  zookeeper-log:

  kafka-data:



networks:

  kafka-net:

    driver: bridge

./.git/config

[core]

	repositoryformatversion = 0

	filemode = true

	bare = false

	logallrefupdates = true

[remote "origin"]

	url = git@github.com:gary003/event_api_kafka_node.git

	fetch = +refs/heads/*:refs/remotes/origin/*

[branch "master"]

	remote = origin

	merge = refs/heads/master

	vscode-merge-base = origin/master

./.git/COMMIT_EDITMSG

Arrange the scrapping function

./.git/packed-refs

# pack-refs with: peeled fully-peeled sorted 

e4e9ea80da2a1e644ca8262052ffaca6c03e9a2b refs/remotes/origin/master

./.git/index

DIRC      hKbéΩÚhKbéΩÚ  ˙\˚  Å§  Ë  Ë  Û=l:3(¶<∏X:µé‡ÖR ˇ 	README.md h≈ïiÏg˘Û*„ûı  ˙ı  Å§  Ë  Ë   Ç€ÁÀïâMî+q¿˙*™:óà¶9 api/.c8rc.json    h≈4lg˘Û,ºõ¯  ˚†  Å§  Ë  Ë  Ü?üwåƒr,–5£~ØŒeÎ!gN api/.gitignore    h≈ KﬁÜg˘Û/®π  ˚°  Å§  Ë  Ë   Ã^õ∞¡‡§d^n`‹*1nT1ê(E api/.prettierrc   h≈*»°àg˚é K¬  ˙Ù˝  Å§  Ë  Ë  N¥ö (√eB¥'x°OA"Ä£Sk“ api/Dockerfile    h≈0q  g˘â“Nö  ˙Ù˛  Å§  Ë  Ë  äNÌP<*ÔŒ{nŸöM8D©ò api/eslint.config.mjs     h≈2µt‰g˚±p‡Ω  ˙Vè  Å§  Ë  Ë Œœ- ºNp‘/PïLÛ!´‰Ôƒ api/package-lock.json     h3⁄:‹ÿ:h3⁄:‹ÿ:  ˙Ùˇ  Å§  Ë  Ë  Aå≥›

èÕÃ<r_¢t	ipºE≠ api/package.json  g¸ÙÌãZ\g¸ÙÌãZ\  ˚h  Å§  Ë  Ë  Ñ©˜∫-ùuèÇiPÄv«·˘Ñ api/src/app.ts    h  ˇ#‰h  ˇ#‰  ˚j  Å§  Ë  Ë  ”≠ã˙"≈r!H¶5.«h™»U≈g api/src/bin/server.ts     h˚<Ûœh˚<Ûœ  ˚„  Å§  Ë  Ë   ¢Ê¬IZópû”Îo„-†yΩπ api/src/routes/eventRoutes.ts     g˛‹‚òg˛‹‚ò  ˙U‰  Å§  Ë  Ë  ∂•5üåÁá(%['‚2ái’ôj api/src/services/consumer.ts      g˝˛œ’◊eg˝˛œ’◊e  ˚◊  Å§  Ë  Ë  Ü9 -u˙QËíT~õ ¡®Á ®C  api/src/services/kafkaService.ts  h∆g∂Zg˘åÛÂÂ  ˙ı  Å§  Ë  Ë  (Õ†r=Ù2IÖŒØf´Éh‡NVû•¶ api/tsconfig.json h7π .h7π .  ˝ó  Å§  Ë  Ë  -—Rwp˘á©∞ÿw'3ﬁ∂Ÿﬁ'∞˘ data_generator/.gitignore h®/&Ÿ\h®/&Ÿ\  ¸Ëv  Å§  Ë  Ë  Où¸Ì¶ÔzxPŸ}%ô·tg/ data_generator/Dockerfile hÆ±ª˛¿hÆ±ª˛¿  ¸Ëu  Å§  Ë  Ë  Âf÷¥Í∞«íÏÛ

‚˚HjpΩ.S´ data_generator/README.md  hãn	®Úçhãn	®Úç  ¸Ëh  Å§  Ë  Ë  .8O$Agz">"¸Hóàø¬R»˝cØ  data_generator/package-lock.json  hø∞.eÔ˘hø∞.eÔ˘  ¸Ëi  Å§  Ë  Ë  ¯‘èõU„w]D>>p*≈*VŸ£ data_generator/package.json       h‰hÚgh‰hÚg .  Å§  Ë  Ë  £¯£Azé5ﬁXä}¯Ä ±ÆÈg data_generator/src/v1/index.ts    hπà9?hπà9?  ¸Ëk  Å§  Ë  Ë  ûo!âNπuD0KˇÀ‚3pÛ data_generator/tsconfig.json      hßé)¢{hßé)¢{  ˙]  Å§  Ë  Ë  _»¶åBM.Ú2Ä≈<}NI7Ö&Í docker-compose.yaml       hµ·$ì.6hµ·$ì.6  ¸   Å§  Ë  Ë   ïÒ•VøŸ®Öñ

5~hºΩ} tsconfig.json     TREE   23 2

ã÷	É‰b‹œS.ñì‰hœ›ßm§api 13 1

Æ¨å»Ú©Õ<¡é™\X•Ôsrc 5 3

≤„˘CÙM≈ÆΩ‹\U=1,Úbin 1 0

Œã8#_4Bi/,lª˘@–Iù§routes 1 0

3oï$Ñï9cﬁ#à6s›‚ó≠Hservices 2 0

2:K"Öìı‰Œo⁄cı’~ÈÇQ6data_generator 7 1

ûlJ·ìÆˇÔì}¸¯g3xkjósrc 1 1

v±nÌƒ¢¯§†q¯Ünf_‡º¸xjv1 1 0

3Rt$Ö∫îª9Öù#p¯—lÀ\†Àn D†S!÷ØÑ≤æ≤ 9≈Ô£./.git/description

Unnamed repository; edit this file 'description' to name the repository.

./.git/HEAD

ref: refs/heads/master

./Dockerfile

# Stage 1: Build stage

FROM node:23-slim AS builder



WORKDIR /app



# Copy package files first to leverage Docker cache

COPY package*.json ./

COPY tsconfig.json ./

COPY .c8rc.json ./



# Install all dependencies including devDependencies

RUN npm ci



# Copy source files

COPY src ./src

COPY eslint.config.mjs ./



# Build the project

RUN npm run build



# Stage 2: Production stage

FROM node:23-slim



WORKDIR /app



# Copy package files

COPY package*.json ./



# Install production dependencies only

RUN npm ci --only=production



# Copy build artifacts from builder

COPY --from=builder /app/dist ./dist



# Expose the application port

EXPOSE 3000



# Start the application

CMD ["node", "./dist/bin/server.js"]./src/bin/server.ts

import http from 'http'

import app from '../app'

import { runConsumer } from '../messageQ/consumer'

import { producer } from '../messageQ/initMQ'



// Create HTTP server

const server = http.createServer(app)

const port = process.env.PORT || '3000'



// Check Kafka connectivity by connecting producer and sending a test message

const checkKafkaConnectivity = async () => {

  try {

    await producer.connect()

    // Optional: Send a test message to ensure topic creation and broker readiness

    await producer.send({

      topic: 'test-connectivity',

      messages: [{ value: JSON.stringify({ test: 'ping' }) }]

    })

    console.info('Kafka broker is fully reachable and operational')

    await producer.disconnect()

    return true

  } catch (error) {

    console.error('Kafka broker not reachable:', error)

    return false

  }

}



// Start Kafka consumer with retry and connectivity check

const startConsumerWithRetry = async (retries = 5, delay = 5000) => {

  for (let attempt = 1; attempt <= retries; attempt++) {

    console.info(`Checking Kafka connectivity (attempt ${attempt}/${retries})`)

    const kafkaReady = await checkKafkaConnectivity()

    if (kafkaReady) {

      try {

        console.info('Starting Kafka consumer...')

        await runConsumer()

        console.info('Kafka consumer started successfully')

        return

      } catch (err) {

        console.error(`Failed to start Kafka consumer: ${err}`)

      }

    } else {

      console.warn('Kafka not fully ready yet')

    }



    if (attempt === retries) {

      console.error('Max retries reached. Exiting...')

      process.exit(1)

    }

    console.info(`Retrying in ${delay / 1000} seconds...`)

    await new Promise((resolve) => setTimeout(resolve, delay))

  }

}



// Start server and consumer

const startServer = async () => {

  try {

    await startConsumerWithRetry()

    server.listen(port)

  } catch (err) {

    console.error('Unexpected error starting server:', err)

    process.exit(1)

  }

}



startServer()



server.on('error', onError)

server.on('listening', onListening)



// Handle graceful shutdown

process.on('SIGTERM', () => shutdown('SIGTERM'))

process.on('SIGINT', () => shutdown('SIGINT'))



/**

 * Event listener for HTTP server "error" event.

 */

function onError(error: NodeJS.ErrnoException) {

  if (error.syscall !== 'listen') {

    throw error

  }



  const bind = typeof port === 'string' ? `Pipe ${port}` : `Port ${port}`



  if (error.code === 'EACCES') {

    console.error(`${bind} requires elevated privileges`)

    process.exit(1)

  } else if (error.code === 'EADDRINUSE') {

    console.error(`${bind} is already in use`)

    process.exit(1)

  } else {

    throw error

  }

}



/**

 * Event listener for HTTP server "listening" event.

 */

function onListening() {

  const addr = server.address()

  const bind = typeof addr === 'string' ? `pipe ${addr}` : `port ${addr?.port}`

  console.info(`Server listening on ${bind}`)

}



/**

 * Graceful shutdown handler

 */

function shutdown(signal: string) {

  console.info(`Received ${signal}. Shutting down gracefully...`)

  server.close(() => {

    console.info('HTTP server closed.')

    process.exit(0)

  })



  setTimeout(() => {

    console.error('Could not close connections in time, forcefully shutting down')

    process.exit(1)

  }, 10000)

}

./src/routes/eventRoutes.ts

import express, { Response } from 'express'



const router = express.Router()



router.route('/').get((_, res: Response) => {

  res.status(200).json({ data: 2 })

})



export default router

./src/app.ts

import express, { Application, Request, Response } from 'express'

import cors from 'cors'

import helmet from 'helmet'

import dotenv from 'dotenv'

import eventRoutes from './routes/eventRoutes'



// Load environment variables

dotenv.config()



// Initialize Express app

const app: Application = express()



// Middleware

app.use(helmet()) // Security headers

app.use(cors()) // Enable CORS for cross-origin requests

app.use(express.json()) // Parse JSON bodies

app.use(express.urlencoded({ extended: true })) // Parse URL-encoded bodies



// Routes

app.use('/api/events', eventRoutes) // Event-related endpoints



// Health check endpoint

app.get('/health', (req: Request, res: Response) => {

  res.status(200).json({ status: 'OK', uptime: process.uptime() })

})



// Handle 404 errors

app.use((req: Request, res: Response) => {

  res.status(404).json({ message: 'Route not found' })

})



export default app

./src/messageQ/initMQ.ts

import { Kafka, Partitioners } from 'kafkajs'



// Initialize Kafka client

const kafka = new Kafka({

  clientId: 'event-api',

  brokers: [process.env.KAFKA_BROKERS || ''] // e.g., ['kafka:9092']

})



// Create producer with legacy partitioner to avoid warning

export const producer = kafka.producer({

  createPartitioner: Partitioners.LegacyPartitioner

})



// Create consumer

export const consumer = kafka.consumer({ groupId: 'event-group' })

./src/messageQ/consumer.ts

import { consumer } from './initMQ'



export const runConsumer = async () => {

  try {

    await consumer.connect()

    await consumer.subscribe({ topic: 'event.created', fromBeginning: true })

    await consumer.run({

      eachMessage: async ({ message }) => {

        try {

          const eventData = '{????????????????}' + message

          //   await EventModel.create({

          //     type: eventData.type,

          //     data: eventData.data,

          //     source: eventData.source || 'kafka'

          //   })

          console.info(`Processed event: ${eventData} ; message : ${message} on topic`)

        } catch (error) {

          console.error('Error processing message on topic -!!!!!!!!!!!!!!!!!!!!!!!!!!!:', error)

        }

      }

    })

  } catch (error) {

    console.error('Kafka consumer error:', error)

    throw error

  }

}



// Handle consumer shutdown

process.on('SIGTERM', async () => {

  console.info('Disconnecting Kafka consumer...')

  await consumer.disconnect()

  console.info('Kafka consumer disconnected')

})

./src/messageQ/producer.ts

import { producer } from './initMQ'



/**

 * Publish an event to a Kafka topic

 */

export const publishEvent = async (topic: string, message: string) => {

  try {

    await producer.connect()

    await producer.send({

      topic,

      messages: [{ value: JSON.stringify(message) }]

    })

    console.info(`Published event to topic ${topic}`)

  } catch (error) {

    console.error(`Failed to publish event to ${topic}:`, error)

    throw error

  } finally {

    await producer.disconnect()

  }

}

./src/data_generator/index.ts

import { setTimeout } from 'timers/promises'



const REQUEST_INTERVAL = 6000



let lastRequestTime = 0



const fetchWithRateLimit = async () => {

  const planetsArr = ['nova', 'black hole', 'star', 'comet', 'dwarf']

  const planetsCount = Math.floor(Math.random() * 1000)



  const planetIndex = Math.floor(Math.random() * planetsArr.length)

  const data = `Found in picture - ${planetsCount} ${planetsArr[planetIndex]}(s)`



  return {

    data,

    timestamp: Date.now()

  }

}



const run = async () => {

  while (true) {

    const now = Date.now()

    const timeSinceLastRequest = now - lastRequestTime



    // Enforce rate limiting

    if (timeSinceLastRequest < REQUEST_INTERVAL) {

      const waitTime = REQUEST_INTERVAL - timeSinceLastRequest

      await setTimeout(waitTime)

    }



    const response = await fetchWithRateLimit().catch((err) => null)



    await setTimeout(REQUEST_INTERVAL)



    // console.log({response})



    if (!!response) {

      console.log(`Astronomy - ${JSON.stringify(response)}`)



      lastRequestTime = Number(response.timestamp)



      // Add your Kafka producer logic here:

      // await producer.send({...});

    }

  }

}



run().catch(console.error)

./eslint.config.mjs

import eslint from '@typescript-eslint/eslint-plugin'

import tsParser from '@typescript-eslint/parser'



export default [

  {

    files: ['**/*.ts'],

    ignores: ['**/node_modules/**', '**/dist/**', '**/build/**', '**/coverage/**', '**/logs/**', '**/entity.ts'], // Ignore build and dependency folders

    plugins: {

      '@typescript-eslint': eslint

    },

    languageOptions: {

      parser: tsParser,

      parserOptions: {

        ecmaVersion: 'latest',

        sourceType: 'module'

      }

    },

    rules: {

      // General Code Quality Rules

      'no-unused-vars': 'warn', // Disable base rule in favor of @typescript-eslint/no-unused-vars

      '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_', varsIgnorePattern: '^_' }], // Allow unused variables starting with `_`

      '@typescript-eslint/no-explicit-any': 'warn', // Warn against using `any` type

      // '@typescript-eslint/explicit-function-return-type': 'warn', // Encourage explicit return types for functions

      // '@typescript-eslint/no-inferrable-types': 'warn', // Disallow explicit type declarations when they can be inferred

      // '@typescript-eslint/no-empty-function': 'warn', // Warn against empty functions



      // Style and Formatting Rules

      indent: ['error', 2], // Enforce 2-space indentation

      quotes: ['error', 'single'] // Enforce single quotes

      // 'object-curly-spacing': ['error', 'always'], // Enforce spaces inside curly braces

      // 'array-bracket-spacing': ['error', 'never'], // Disallow spaces inside array brackets

      // 'space-before-function-paren': ['error', 'never'], // No space before function parentheses

    }

  }

]

./README.md

# event API nodejs - typescript



## Description



This repository is a backend event api streaming crypto data from coin gecko.



## Prerequisites



- Having docker(v27+) & docker-compose(v2.20) installed



!! A docker group must be created, then your user(sudoer) is added to it.

Otherwise you'll have trouble launching the tests !!



Link to install and configure docker properly :



    https://medium.com/devops-technical-notes-and-manuals/how-to-run-docker-commands-without-sudo-28019814198f



Don't forgot to restart your computer or session for the changes to be available on all shells



## Git Installation



- Clone the project



  `git clone https://github.com/gary003/event_api_nodejs_typescript.git`



- Go into the project directory



  `cd event_api_nodejs_typescript`



- Install the dependences



  `npm install`



## Start API



- Launch the data generation api



  `docker-compose up data_generator`



## Developer



- Gary Johnson

  - mail: gary.johnson.freelance@gmail.com

  - github: https://github.com/gary003



## License



    [MIT]

